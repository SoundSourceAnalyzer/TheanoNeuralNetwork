{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the imports are not useful yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import theano\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Masking\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D, Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n",
      "<type 'float'>\n",
      "Pop\n",
      "{'Classical': 0, 'Jazz': 1, 'Metal': 2, 'Pop': 3, 'Rock': 4, 'Blues': 5}\n",
      "set([0, 1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "dataset_xs = []\n",
    "dataset_y = []\n",
    "with open('data/ismis.csv', 'rb') as csvfile:\n",
    "    next(csvfile) # skip header\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        features_strings = row[1:147] + row[168:191] \n",
    "        dataset_xs.append(map(float, features_strings)) # features\n",
    "        dataset_y.append(row[-1]) # genre\n",
    "    \n",
    "print(len(dataset_xs[0]))\n",
    "print(type(dataset_xs[0][0]))\n",
    "print(dataset_y[0])\n",
    "\n",
    "classes = set(dataset_y)\n",
    "nb_classes = len(classes)\n",
    "mappings = dict(enumerate(classes))\n",
    "mappings_rev = {v: k for k, v in mappings.items()}\n",
    "print(mappings_rev)\n",
    "dataset_y_mapped = map(lambda x: mappings_rev[x], dataset_y)\n",
    "print(set(dataset_y_mapped))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evens(dataset):\n",
    "    return dataset[::2]\n",
    "def odds(dataset):\n",
    "    return dataset[1::2]\n",
    "\n",
    "train_dataset_xs = odds(dataset_xs)\n",
    "train_dataset_y = odds(dataset_y_mapped)\n",
    "test_dataset_xs = evens(dataset_xs)\n",
    "test_dataset_y = evens(dataset_y_mapped)\n",
    "\n",
    "def randomize(dataset_xs, dataset_y):\n",
    "    permutation = np.random.permutation(len(dataset_y))\n",
    "    shuffled_dataset_xs = np.asarray(dataset_xs)[permutation]\n",
    "    shuffled_dataset_y = np.asarray(dataset_y)[permutation]\n",
    "    return shuffled_dataset_xs, shuffled_dataset_y\n",
    "\n",
    "train_dataset_xs, train_dataset_y = randomize(train_dataset_xs,train_dataset_y)\n",
    "test_dataset_xs, test_dataset_y = randomize(test_dataset_xs, test_dataset_y)\n",
    "\n",
    "try:\n",
    "    f = open('data/ismis_randomized.pickle', 'wb')\n",
    "    save = {\n",
    "        'train_dataset_xs': train_dataset_xs,\n",
    "        'train_dataset_y': train_dataset_y,\n",
    "        'test_dataset_xs': test_dataset_xs,\n",
    "        'test_dataset_y': test_dataset_y,\n",
    "        'mappings': mappings\n",
    "    }\n",
    "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start here\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6247, 169)\n"
     ]
    }
   ],
   "source": [
    "with open('data/ismis_randomized.pickle', 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset_xs = save['train_dataset_xs']\n",
    "    train_dataset_y = save['train_dataset_y']\n",
    "    test_dataset_xs = save['test_dataset_xs']\n",
    "    test_dataset_y = save['test_dataset_y']\n",
    "    del save  # gc\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(train_dataset_y, nb_classes)\n",
    "y_test = np_utils.to_categorical(test_dataset_y, nb_classes)\n",
    "\n",
    "print(train_dataset_xs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Training & Testing:\n",
    "========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "\n",
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 169\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "nb_filter = 250\n",
    "filter_length = 3\n",
    "hidden_dims = 250\n",
    "nb_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(len(train_dataset_xs), 'train sequences')\n",
    "print(len(test_dataset_xs), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "train_dataset_xs = sequence.pad_sequences(train_dataset_xs, maxlen=maxlen)\n",
    "test_dataset_xs = sequence.pad_sequences(test_dataset_xs, maxlen=maxlen)\n",
    "print('X_train shape:', train_dataset_xs.shape)\n",
    "print('X_test shape:', test_dataset_xs.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# # we start off with an efficient embedding layer which maps\n",
    "# # our vocab indices into embedding_dims dimensions\n",
    "# model.add(Embedding(max_features,\n",
    "#                     embedding_dims,\n",
    "#                     input_length=maxlen,\n",
    "#                     dropout=0.2))\n",
    "\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "\n",
    "def max_1d(X):\n",
    "    return K.max(X, axis=1)\n",
    "\n",
    "model.add(Lambda(max_1d, output_shape=(nb_filter,)))\n",
    "\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(6))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_dataset_xs, y_train,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=nb_epoch,\n",
    "          validation_data=(test_dataset_xs, y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
